{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from wordcloud import WordCloud \n",
    "from flask import Flask, render_template, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(tfidf_transformer,lgbm_model,nn_model,tfidf2_dict,note_list):\n",
    "    lgbm_input=tfidf_transformer.transform(note_list)\n",
    "    lgbm_prob_output=lgbm_model.predict_proba(lgbm_input)[0, 1]\n",
    "    lgbm_contri_output=lgbm_model.predict_proba(lgbm_input,pred_contrib=True).tolist()[0]\n",
    "    nn_unpadded_input=[[tfidf2_dict[word] for word in note.split() if word in tfidf2_dict.keys()] for note in note_list]\n",
    "    maxlen=1000\n",
    "    nn_padded_input=pad_sequences(nn_unpadded_input, dtype='float32', padding='post', maxlen=maxlen)\n",
    "    nn_output=nn_model.predict(nn_padded_input)[0,0]\n",
    "    \n",
    "    return lgbm_prob_output,nn_output,lgbm_contri_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_cloud(importance_dict):\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                          background_color ='white', \n",
    "                          min_font_size = 10).generate_from_frequencies(importance_dict) \n",
    "    \n",
    "    img = io.BytesIO()\n",
    "    \n",
    "    plt.figure(figsize = (6,6), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "\n",
    "    plt.savefig(img, format='png')\n",
    "    img.seek(0)\n",
    "    graph_url = base64.b64encode(img.getvalue()).decode()\n",
    "    plt.close()\n",
    "    return 'data:image/png;base64,{}'.format(graph_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_waterfall(prob_list,prob_source_name_list):\n",
    "    trans = pd.DataFrame(data={'Importance': prob_list},index=prob_source_name_list).sort_values(by=['Importance'])\n",
    "    blank=trans.Importance.cumsum().shift(1).fillna(0)\n",
    "    total = trans.sum().Importance\n",
    "    trans.loc[\"net\"] = -total\n",
    "    blank.loc[\"net\"] = total\n",
    "    step = blank.reset_index(drop=True).repeat(3).shift(-1)\n",
    "    step[1::3] = np.nan\n",
    "    \n",
    "    img = io.BytesIO()\n",
    "    my_plot = trans.plot(kind='bar',\n",
    "                         stacked=True,\n",
    "                         bottom=blank,legend=None,\n",
    "                         title=\"Predicted Probability Waterfall Chart\",\n",
    "                         ylim=(-0.5,1.5),\n",
    "                         figsize=(6,6))\n",
    "    my_plot.plot(step.index, step.values,'k')\n",
    "    \n",
    "    plt.savefig(img, format='png', bbox_inches='tight')\n",
    "    img.seek(0)\n",
    "    graph_url = base64.b64encode(img.getvalue()).decode()\n",
    "    plt.close()\n",
    "    return 'data:image/png;base64,{}'.format(graph_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def homepage():\n",
    "    return render_template('homepage.html')\n",
    "\n",
    "@app.route('/analysis')\n",
    "def analysispage():\n",
    "    return render_template('analysis.html')\n",
    "\n",
    "@app.route('/about')\n",
    "def aboutpage():\n",
    "    return render_template('about.html')\n",
    "\n",
    "@app.route('/contact')\n",
    "def contactpage():\n",
    "    return render_template('contact.html')\n",
    "\n",
    "@app.route('/results', methods=['POST', 'GET'])\n",
    "def resultspage():\n",
    "    try:\n",
    "        note = request.form[\"note_input\"]\n",
    "    except:\n",
    "        return render_template(\"analysis.html\")\n",
    "    if note.strip()=='' or note==None:\n",
    "        return render_template(\"analysis.html\")\n",
    "    \n",
    "    threshhold=0.5\n",
    "    icd9_list=['4019','41401','4280','42731']\n",
    "    result_list=[]\n",
    "    for icd9 in icd9_list:\n",
    "        tfidf2_dict = dill.load(open('data/tfidf2_dict.dict', 'rb'))\n",
    "        tfidf_transformer = dill.load(open('model/'+icd9+'_tfidf_transformer.fitted', 'rb'))\n",
    "        lgbm_model = dill.load(open('model/'+icd9+'_lgbm_model.fitted', 'rb'))\n",
    "        nn_model=load_model('model/'+icd9+'_nn_model_fitted.h5')  \n",
    "    \n",
    "        lgbm_prob_output,nn_output,lgbm_contri_output=make_pred(tfidf_transformer,lgbm_model,nn_model,tfidf2_dict,[note])\n",
    "        del tfidf2_dict\n",
    "        del nn_model\n",
    "        \n",
    "        if lgbm_prob_output+nn_output>threshhold:\n",
    "            del lgbm_prob_output\n",
    "            lgbm_importance_list=lgbm_model.feature_importances_.tolist()\n",
    "            del lgbm_model\n",
    "            lgbm_min_importance=min([i for i in lgbm_importance_list if i!=0])/10\n",
    "            lgbm_importance_list_fixed=[lgbm_min_importance if i==0 else i for i in lgbm_importance_list]\n",
    "            del lgbm_min_importance\n",
    "            lgbm_feature_name_list=tfidf_transformer.get_feature_names()\n",
    "            del tfidf_transformer\n",
    "            importance_dict=dict((i,j) for (i,j) in zip(lgbm_feature_name_list, lgbm_importance_list_fixed) if j!=0)\n",
    "            del lgbm_importance_list\n",
    "            del lgbm_importance_list_fixed\n",
    "            graph1_url = build_word_cloud(importance_dict)\n",
    "            del importance_dict\n",
    "\n",
    "            prob_cum_list=list(1/(1+np.exp(-np.cumsum(lgbm_contri_output))))\n",
    "            del lgbm_contri_output\n",
    "            prob_cum_list.insert(0,0)\n",
    "            prob_list=list(np.diff(prob_cum_list))\n",
    "            prob_list.append(min(max(prob_cum_list[-1]+nn_output,0),1)-prob_cum_list[-1])\n",
    "            del nn_output\n",
    "            del prob_cum_list\n",
    "            prob_source_name_list=['Intercept']\n",
    "            prob_source_name_list.extend(lgbm_feature_name_list)\n",
    "            prob_source_name_list.append('convolutional neural network')\n",
    "            graph2_url = build_waterfall(prob_list,prob_source_name_list)\n",
    "            del prob_source_name_list\n",
    "            \n",
    "            result_list.append((icd9+': '+max(lgbm_feature_name_list, key=len)+' is a potential ICD-9 with probability '+\"{0:.4f}\".format(sum(prob_list))+'.',\n",
    "                           graph1_url,graph2_url))\n",
    "            del lgbm_feature_name_list\n",
    "            del prob_list\n",
    "            del graph1_url\n",
    "            del graph2_url\n",
    "        else:\n",
    "            del lgbm_prob_output\n",
    "            del nn_output\n",
    "            del lgbm_contri_output\n",
    "            \n",
    "    del threshhold\n",
    "    del icd9_list\n",
    "    del note\n",
    "\n",
    "    if result_list==[]:\n",
    "        result_list.append(('empty',None,None))\n",
    "            \n",
    "    return render_template('results.html',\n",
    "                           result_list=result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:4799/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Sep/2019 02:19:18] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [22/Sep/2019 02:19:20] \"\u001b[37mGET /analysis HTTP/1.1\u001b[0m\" 200 -\n",
      "[2019-09-22 02:19:34,691] ERROR in app: Exception on /results [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-6-8ae8a9d98623>\", line 31, in resultspage\n",
      "    tfidf_transformer = dill.load(open('model/'+icd9+'_tfidf_transformer.fitted', 'rb'))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'model/5849_tfidf_transformer.fitted'\n",
      "127.0.0.1 - - [22/Sep/2019 02:19:34] \"\u001b[1m\u001b[35mPOST /results HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(port=4799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
